{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from thyroid.utils.exception import customException\n",
    "import requests\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\aakas\\Documents\\Projects\\Thyroid-disease-detection\\research\n"
     ]
    }
   ],
   "source": [
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\aakas\\\\Documents\\\\Projects\\\\Thyroid-disease-detection'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Download and extract the data-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/static/public/102/thyroid+disease.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the data will be extracted\n",
    "directory = 'raw_data'\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the file\n",
    "response = requests.get(url)\n",
    "file_name = url.split('/')[-1]  # Extracting the file name from the URL\n",
    "file_path = os.path.join(directory, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the downloaded file\n",
    "with open(file_path, 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# Extract the downloaded zip file\n",
    "with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(directory)\n",
    "\n",
    "# Remove the zip file after extraction\n",
    "os.remove(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 read all the files and find total number of data in each dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_directory = \"raw_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_rows_in_file(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        return sum(1 for _ in file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observing no. of entries in .data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: allbp.data, Rows: 2800\n",
      "File: allhyper.data, Rows: 2800\n",
      "File: allhypo.data, Rows: 2800\n",
      "File: allrep.data, Rows: 2800\n",
      "File: ann-test.data, Rows: 3428\n",
      "File: ann-train.data, Rows: 3772\n",
      "File: dis.data, Rows: 2800\n",
      "File: hypothyroid.data, Rows: 3163\n",
      "File: new-thyroid.data, Rows: 215\n",
      "File: sick-euthyroid.data, Rows: 3163\n",
      "File: sick.data, Rows: 2800\n",
      "File: thyroid0387.data, Rows: 9172\n"
     ]
    }
   ],
   "source": [
    "file_extension = \".data\"\n",
    "\n",
    "for filename in os.listdir(raw_directory):\n",
    "    if filename.endswith(file_extension):\n",
    "        file_path = os.path.join(raw_directory, filename)\n",
    "        row_count = count_rows_in_file(file_path)\n",
    "        print(f\"File: {filename}, Rows: {row_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data size of allbp, allhyper, allhypo, allrep, dis and sick is exactly 2800 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: allbp.test, Rows: 972\n",
      "File: allhyper.test, Rows: 972\n",
      "File: allhypo.test, Rows: 972\n",
      "File: allrep.test, Rows: 972\n",
      "File: dis.test, Rows: 972\n",
      "File: sick.test, Rows: 972\n"
     ]
    }
   ],
   "source": [
    "file_extension = \".test\"\n",
    "\n",
    "for filename in os.listdir(raw_directory):\n",
    "    if filename.endswith(file_extension):\n",
    "        file_path = os.path.join(raw_directory, filename)\n",
    "        row_count = count_rows_in_file(file_path)\n",
    "        print(f\"File: {filename}, Rows: {row_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can observe that all entries in allbp, allhyper, allhypo, allrep, dis and sick  in test file is exactly 972 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = '41,F,f,f,f,f,f,f,  f,f,f,f,f,f,f,f,t,1.3,t,2.5,t,125,t,1.14,t,109,f,?,SVHC,negative.|3733\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['41,F,f,f,f,f,f,f,  f,f,f,f,f,f,f,f,t,1.3,t,2.5,t,125,t,1.14,t,109,f,?,SVHC,negative.|3733']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = row.strip().split('\\n')\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "c =[]\n",
    "cls = []\n",
    "for attribute in row.strip().split(','):\n",
    "     if '.|' in attribute:\n",
    "        c.append(attribute.split('.|')[0])\n",
    "        cls.append(attribute.split('.|')[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3733']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can observe that allbp, allhyper, allhypo, allrep, dis and sick all have 2800 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets check what classes each data have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels_from_file(file_path):\n",
    "    #if file_path.lower().endswith('.data' or '.test'):\n",
    "    unique_labels = set()\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = file.readlines()\n",
    "        for row in data:\n",
    "            rw = row.strip().split('\\n')  # Split input into rows\n",
    "            for attribute in row.strip().split(','):\n",
    "                if '.|' in attribute:\n",
    "                    unique_labels.add(attribute.split('.|')[0])\n",
    "    return unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allbp.data : {'negative', 'decreased binding protein', 'increased binding protein'}\n",
      "allhyper.data : {'goitre', 'negative', 'T3 toxic', 'hyperthyroid'}\n",
      "allhypo.data : {'negative', 'secondary hypothyroid', 'primary hypothyroid', 'compensated hypothyroid'}\n",
      "allrep.data : {'replacement therapy', 'negative', 'underreplacement', 'overreplacement'}\n",
      "dis.data : {'negative', 'discordant'}\n",
      "sick.data : {'negative', 'sick'}\n"
     ]
    }
   ],
   "source": [
    "dataset_filenames = [\"allbp.data\", \"allhyper.data\", \"allhypo.data\", \"allrep.data\", \"dis.data\", \"sick.data\"]\n",
    "# Define a set to store unique class labels\n",
    "\n",
    "\n",
    "# Loop through each dataset file\n",
    "for filename in dataset_filenames:\n",
    "    file_path = os.path.join(raw_directory, filename)  # Assuming the files are in the \"raw\" folder\n",
    "    if os.path.exists(file_path):\n",
    "        ul = extract_labels_from_file(file_path)\n",
    "        print(f\"{filename} : {ul}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allhyper.test : {'T3 toxic', 'hyperthyroid', 'secondary toxic', 'negative', 'goitre'}\n",
      "allhypo.test : {'negative', 'primary hypothyroid', 'compensated hypothyroid'}\n"
     ]
    }
   ],
   "source": [
    "dataset_filenames = [ \"allhyper.test\", \"allhypo.test\"]\n",
    "# Define a set to store unique class labels\n",
    "\n",
    "\n",
    "# Loop through each dataset file\n",
    "for filename in dataset_filenames:\n",
    "    file_path = os.path.join(raw_directory, filename)  # Assuming the files are in the \"raw\" folder\n",
    "    if os.path.exists(file_path):\n",
    "        ul = extract_labels_from_file(file_path)\n",
    "        print(f\"{filename} : {ul}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have observed that there are 2800 patients ID and it is possibility that they are same in all these files, by checking data generally\n",
    "\n",
    "The files allbp, allrep, dis, sick all contains therapies and data is almost identical with all hyper and hypo so we will consider only data from allhyper and allhypo files and discard rest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_remove = ['allbp.data','allrep.data','dis.data','sick.data','allbp.test','allrep.test','dis.test','sick.test','allbp.name','allrep.name','dis.name','sick.name']\n",
    "for file_name in files_to_remove:\n",
    "    file_path = os.path.join(raw_directory, file_name)\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
